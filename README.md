# object_detection_project
This project is designed to empower visually impaired individuals by providing real-time object detection and audio feedback to help them navigate their surroundings with greater independence and confidence. Leveraging advanced machine learning and computer vision techniques, the system identifies objects in the user's environment and communicates their presence audibly.

Key Features:
Real-Time Object Detection:
The system utilizes deep learning models like YOLO (You Only Look Once) or SSD (Single Shot Multibox Detector) for fast and accurate object detection.

Audio Feedback:
Detected objects are announced to the user via text-to-speech (TTS) technology, enabling quick and intuitive awareness of surroundings.

Customizable Object Categories:
The system allows customization of detectable objects based on user preferences or specific requirements, such as detecting doors, people, or vehicles.

Portable and User-Friendly Design:
Built for lightweight hardware like Raspberry Pi, with camera integration for mobility, ensuring it is easy to use on the go.

Edge or Cloud Processing:
Offers flexibility to process data on edge devices for faster response times or use cloud computing for more extensive model capabilities.

Technologies Used:
Programming Language: Python
Libraries and Frameworks: OpenCV, TensorFlow/PyTorch, gTTS or Pyttsx3 for TTS
Hardware Requirements: Camera module, microphone, headphones/speakers (for audio output)
